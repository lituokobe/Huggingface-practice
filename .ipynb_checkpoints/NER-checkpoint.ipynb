{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93ac3efa-5b0c-407a-a1c3-d677da61a627",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7a7f4f-860b-49a6-9d4a-ffa8b8580349",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b07af035-cf00-426e-90f2-4a9a4f136c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0316f3a6-8e1c-4042-8e60-06cf3c136989",
   "metadata": {},
   "source": [
    "### 2. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c924986-e9f0-405e-a63f-4ca602deadbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_dataset = load_dataset(\"arrow\", data_dir = \"./peoples_daily_ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e317e3a-fcd6-4670-9d7c-537518b17af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 20865\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 2319\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 4637\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ea10248-9696-4b47-946d-5caf79b97580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '4', 'tokens': ['日', '俄', '两', '国', '国', '内', '政', '局', '都', '充', '满', '变', '数', '，', '尽', '管', '日', '俄', '关', '系', '目', '前', '是', '历', '史', '最', '佳', '时', '期', '，', '但', '其', '脆', '弱', '性', '不', '言', '自', '明', '。'], 'ner_tags': [5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(ner_dataset[\"train\"][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7efa4793-5fb1-4c0c-9096-d15ea2c5c28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': Value(dtype='string', id=None),\n",
       " 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_dataset[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c391df4d-d2c7-40ca-9114-7465a34ceb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ner_dataset[\"train\"].features[\"ner_tags\"].feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f20549a-03fd-45be-854b-3035647fa45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "951819f5-4961-48fc-bdd4-17ec01af13f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5525d9-51e6-4c60-a06d-4d3cf4fa9cb5",
   "metadata": {},
   "source": [
    "`ner_tags` has the index of the labels in `label_list`. \n",
    "\n",
    "`label_list` is like a look-up list for the label numbers and the actual label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8cf5dd-85c0-4fda-9a8c-f2fff75b5290",
   "metadata": {},
   "source": [
    "### 4. Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68086af5-7730-498a-b201-5b45e8cd852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"hfl/chinese-macbert-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acaf16b2-2067-4967-a3ed-4723ea4e1012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['海',\n",
       " '钓',\n",
       " '比',\n",
       " '赛',\n",
       " '地',\n",
       " '点',\n",
       " '在',\n",
       " '厦',\n",
       " '门',\n",
       " '与',\n",
       " '金',\n",
       " '门',\n",
       " '之',\n",
       " '间',\n",
       " '的',\n",
       " '海',\n",
       " '域',\n",
       " '。']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_dataset[\"train\"][0][\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9338679a-9ebb-4149-87bd-bb50e47b106b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 3862, 102], [101, 7157, 102], [101, 3683, 102], [101, 6612, 102], [101, 1765, 102], [101, 4157, 102], [101, 1762, 102], [101, 1336, 102], [101, 7305, 102], [101, 680, 102], [101, 7032, 102], [101, 7305, 102], [101, 722, 102], [101, 7313, 102], [101, 4638, 102], [101, 3862, 102], [101, 1818, 102], [101, 511, 102]], 'token_type_ids': [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]], 'attention_mask': [[1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1]]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(ner_dataset[\"train\"][0][\"tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfcbcad-5d0e-4dad-8029-ffa991c2a7c1",
   "metadata": {},
   "source": [
    "Because in the original data, each character is seprated in a string in the list, that's why in the tokenized data, each small list has 3 numbers inside, with 101 as first and 102 as the last. This is not correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4573c785-1722-4b3c-9e7f-a2d2ffc96c74",
   "metadata": {},
   "source": [
    "Adding\n",
    "```python\n",
    "is_split_into_words = True\n",
    "```\n",
    "will let the tokenizer understand the separation of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90f70cc9-b15b-4531-a898-4815fb26fbd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 3862, 7157, 3683, 6612, 1765, 4157, 1762, 1336, 7305, 680, 7032, 7305, 722, 7313, 4638, 3862, 1818, 511, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(ner_dataset[\"train\"][0][\"tokens\"], is_split_into_words = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce167e2d-b785-40f9-8a90-130ab157f549",
   "metadata": {},
   "source": [
    "English words can be conevrt to multiple tokens each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "474af487-419d-4368-8074-1d0d95ee6ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 162, 10477, 10367, 10143, 8794, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"transportation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58c95909-da9a-4367-ab0d-bd1c5c1a793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tokenizer(\"transportation tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0cf7d83-f9dd-4897-9de7-6976b249eae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 162, 10477, 10367, 10143, 8794, 11928, 8178, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63bed647-dc0d-4946-9fde-7e9d9d56e53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 0, 0, 0, 0, 1, 1, None]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc8bf6fa-f49e-4f33-955a-06103fc90aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'##sp'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([10367])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c22e85a1-3e57-461a-9b21-6a690eaef788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_function(examples):\n",
    "    tokenized_examples = tokenizer(examples[\"tokens\"],\n",
    "                                   max_length = 128,\n",
    "                                   truncation = True,\n",
    "                                   padding = True,\n",
    "                                   is_split_into_words = True)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_examples.word_ids(batch_index = i) #get the i-th sample of the example\n",
    "        label_ids = []\n",
    "        #as some word match multiple ids, we need to do some special label assignment\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:\n",
    "                label_ids.append(-100) # ignore None in loss computation\n",
    "            else:\n",
    "                label_ids.append(label[word_id])\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_examples[\"labels\"] = labels\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40239d25-cce4-45ff-a582-7c5beb0817c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = ner_dataset.map(process_function, batched = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c25b8e6f-fe5b-4c90-9d37-ba9d95bcfe29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 20865\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2319\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 4637\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46659fd8-5309-4c67-bdea-2a28770174ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '4', 'tokens': ['日', '俄', '两', '国', '国', '内', '政', '局', '都', '充', '满', '变', '数', '，', '尽', '管', '日', '俄', '关', '系', '目', '前', '是', '历', '史', '最', '佳', '时', '期', '，', '但', '其', '脆', '弱', '性', '不', '言', '自', '明', '。'], 'ner_tags': [5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'input_ids': [101, 3189, 915, 697, 1744, 1744, 1079, 3124, 2229, 6963, 1041, 4007, 1359, 3144, 8024, 2226, 5052, 3189, 915, 1068, 5143, 4680, 1184, 3221, 1325, 1380, 3297, 881, 3198, 3309, 8024, 852, 1071, 5546, 2483, 2595, 679, 6241, 5632, 3209, 511, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [-100, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_datasets[\"train\"][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e3456c-c9cc-457f-86c4-156f3d245d8c",
   "metadata": {},
   "source": [
    "### 5. Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b7ed656-4699-4061-b708-35c1009806ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at hfl/chinese-macbert-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\"hfl/chinese-macbert-large\", num_labels = len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2eb45e60-2acc-429d-b029-796defff6160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.num_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ee7910-dc6f-496f-946a-a11403e00f26",
   "metadata": {},
   "source": [
    "By default, the model will only do 2 label classification. We need to adjust it to our use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce4faedb-31f0-4828-9d36-95ba758d748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.data = param.data.contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3940368-9cad-4ec3-83ce-1b21bdd5630c",
   "metadata": {},
   "source": [
    "### 6. Set up evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "096a2b61-3407-4641-85ae-5d3193f72dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqeval = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e292060-9cd3-4e03-ab37-fe3124405a16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationModule(name: \"seqeval\", module_type: \"metric\", features: {'predictions': Sequence(feature=Value(dtype='string', id='label'), length=-1, id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='label'), length=-1, id='sequence')}, usage: \"\"\"\n",
       "Produces labelling scores along with its sufficient statistics\n",
       "from a source against one or more references.\n",
       "\n",
       "Args:\n",
       "    predictions: List of List of predicted labels (Estimated targets as returned by a tagger)\n",
       "    references: List of List of reference labels (Ground truth (correct) target values)\n",
       "    suffix: True if the IOB prefix is after type, False otherwise. default: False\n",
       "    scheme: Specify target tagging scheme. Should be one of [\"IOB1\", \"IOB2\", \"IOE1\", \"IOE2\", \"IOBES\", \"BILOU\"].\n",
       "        default: None\n",
       "    mode: Whether to count correct entity labels with incorrect I/B tags as true positives or not.\n",
       "        If you want to only count exact matches, pass mode=\"strict\". default: None.\n",
       "    sample_weight: Array-like of shape (n_samples,), weights for individual samples. default: None\n",
       "    zero_division: Which value to substitute as a metric value when encountering zero division. Should be on of 0, 1,\n",
       "        \"warn\". \"warn\" acts as 0, but the warning is raised.\n",
       "\n",
       "Returns:\n",
       "    'scores': dict. Summary of the scores for overall and per type\n",
       "        Overall:\n",
       "            'accuracy': accuracy,\n",
       "            'precision': precision,\n",
       "            'recall': recall,\n",
       "            'f1': F1 score, also known as balanced F-score or F-measure,\n",
       "        Per type:\n",
       "            'precision': precision,\n",
       "            'recall': recall,\n",
       "            'f1': F1 score, also known as balanced F-score or F-measure\n",
       "Examples:\n",
       "\n",
       "    >>> predictions = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
       "    >>> references = [['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
       "    >>> seqeval = evaluate.load(\"seqeval\")\n",
       "    >>> results = seqeval.compute(predictions=predictions, references=references)\n",
       "    >>> print(list(results.keys()))\n",
       "    ['MISC', 'PER', 'overall_precision', 'overall_recall', 'overall_f1', 'overall_accuracy']\n",
       "    >>> print(results[\"overall_f1\"])\n",
       "    0.5\n",
       "    >>> print(results[\"PER\"][\"f1\"])\n",
       "    1.0\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd06327d-f5ce-48f2-815b-47828dd8d0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3703532-f002-48ba-ab3b-10c62542a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric(eval_predict):\n",
    "    predictions, labels = eval_predict\n",
    "    predictions = np.argmax(predictions, axis = -1)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for p, l in zip (prediction, label) if l != -100] #iterate every token_id in the sample\n",
    "        for prediction, label in zip(predictions, labels) #all the samples in one batch\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for p, l in zip (prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels) #all the samples in one batch\n",
    "    ]\n",
    "    result = seqeval.compute(references = true_labels,\n",
    "                             predictions = true_predictions,\n",
    "                             scheme = \"IOB2\",\n",
    "                             mode = \"strict\")\n",
    "    \n",
    "    return {\n",
    "        \"f1\": result[\"overall_f1\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecb8323-917f-4e4d-9413-48606b86720f",
   "metadata": {},
   "source": [
    "### 7. Configure training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33ca10df-e568-4d12-9409-b09bd8eb590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir = \"./modesl_for_ner\",\n",
    "    per_device_train_batch_size = 8,\n",
    "    per_device_eval_batch_size = 128,\n",
    "    logging_steps = 30,\n",
    "    eval_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    metric_for_best_model = \"f1\",\n",
    "    load_best_model_at_end = True , \n",
    "    disable_tqdm = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27d7d420-a446-44cf-bea3-6c5e78092738",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=1,\n",
       "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "average_tokens_across_devices=False,\n",
       "batch_eval_metrics=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_persistent_workers=False,\n",
       "dataloader_pin_memory=True,\n",
       "dataloader_prefetch_factor=None,\n",
       "ddp_backend=None,\n",
       "ddp_broadcast_buffers=None,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=True,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_do_concat_batches=True,\n",
       "eval_on_start=False,\n",
       "eval_steps=None,\n",
       "eval_strategy=epoch,\n",
       "eval_use_gather_object=False,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
       "fsdp_min_num_params=0,\n",
       "fsdp_transformer_layer_cls_to_wrap=None,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "gradient_checkpointing_kwargs=None,\n",
       "greater_is_better=True,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_always_push=False,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=None,\n",
       "hub_revision=None,\n",
       "hub_strategy=every_save,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_for_metrics=[],\n",
       "include_inputs_for_metrics=False,\n",
       "include_num_input_tokens_seen=False,\n",
       "include_tokens_per_second=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=5e-05,\n",
       "length_column_name=length,\n",
       "liger_kernel_config=None,\n",
       "load_best_model_at_end=True,\n",
       "local_rank=0,\n",
       "log_level=passive,\n",
       "log_level_replica=warning,\n",
       "log_on_each_node=True,\n",
       "logging_dir=./modesl_for_ner/runs/Aug14_15-33-09_Tuos-Mac-mini.local,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=30,\n",
       "logging_strategy=steps,\n",
       "lr_scheduler_kwargs={},\n",
       "lr_scheduler_type=linear,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=f1,\n",
       "mp_parameters=,\n",
       "neftune_noise_alpha=None,\n",
       "no_cuda=False,\n",
       "num_train_epochs=3.0,\n",
       "optim=adamw_torch,\n",
       "optim_args=None,\n",
       "optim_target_modules=None,\n",
       "output_dir=./modesl_for_ner,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=128,\n",
       "per_device_train_batch_size=8,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=['tensorboard'],\n",
       "restore_callback_states_from_checkpoint=False,\n",
       "resume_from_checkpoint=None,\n",
       "run_name=./modesl_for_ner,\n",
       "save_on_each_node=False,\n",
       "save_only_model=False,\n",
       "save_safetensors=True,\n",
       "save_steps=500,\n",
       "save_strategy=epoch,\n",
       "save_total_limit=None,\n",
       "seed=42,\n",
       "skip_memory_metrics=True,\n",
       "tf32=None,\n",
       "torch_compile=False,\n",
       "torch_compile_backend=None,\n",
       "torch_compile_mode=None,\n",
       "torch_empty_cache_steps=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_cpu=False,\n",
       "use_ipex=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "use_liger_kernel=False,\n",
       "use_mps_device=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.0,\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b85328-4500-42eb-b491-4c9ab78f6356",
   "metadata": {},
   "source": [
    "### 8. Create trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1113386b-2d31-4fdd-8768-b1fd9f79be74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = args,\n",
    "    train_dataset = tokenized_datasets[\"train\"].select(range(6000)),\n",
    "    eval_dataset = tokenized_datasets[\"validation\"].select(range(1000)),\n",
    "    data_collator = DataCollatorWithPadding(tokenizer = tokenizer),\n",
    "    compute_metrics = eval_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7772255-5ab0-4cfe-ab8e-4b7b592f2b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db0be48b-5da0-41ab-b83a-6d3e9a4927d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2ed4cd-a260-4513-984f-ddd406ab288e",
   "metadata": {},
   "source": [
    "### 9. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47dc6603-48a6-42c2-b22f-2ba8ba5747be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4203, 'grad_norm': 1.7180335521697998, 'learning_rate': 4.935555555555556e-05, 'epoch': 0.04}\n",
      "{'loss': 0.1212, 'grad_norm': 3.8996825218200684, 'learning_rate': 4.868888888888889e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0739, 'grad_norm': 2.683225631713867, 'learning_rate': 4.802222222222223e-05, 'epoch': 0.12}\n",
      "{'loss': 0.1145, 'grad_norm': 4.836878776550293, 'learning_rate': 4.7355555555555555e-05, 'epoch': 0.16}\n",
      "{'loss': 0.108, 'grad_norm': 4.652242660522461, 'learning_rate': 4.668888888888889e-05, 'epoch': 0.2}\n",
      "{'loss': 0.1117, 'grad_norm': 0.708916187286377, 'learning_rate': 4.602222222222222e-05, 'epoch': 0.24}\n",
      "{'loss': 0.0734, 'grad_norm': 3.203871488571167, 'learning_rate': 4.5355555555555554e-05, 'epoch': 0.28}\n",
      "{'loss': 0.0625, 'grad_norm': 6.3980326652526855, 'learning_rate': 4.468888888888889e-05, 'epoch': 0.32}\n",
      "{'loss': 0.0442, 'grad_norm': 0.8283454179763794, 'learning_rate': 4.4022222222222225e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0712, 'grad_norm': 7.60693883895874, 'learning_rate': 4.335555555555556e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0938, 'grad_norm': 7.309241771697998, 'learning_rate': 4.268888888888889e-05, 'epoch': 0.44}\n",
      "{'loss': 0.0828, 'grad_norm': 0.2876698672771454, 'learning_rate': 4.2022222222222223e-05, 'epoch': 0.48}\n",
      "{'loss': 0.0785, 'grad_norm': 1.8635034561157227, 'learning_rate': 4.135555555555556e-05, 'epoch': 0.52}\n",
      "{'loss': 0.0761, 'grad_norm': 0.30554652214050293, 'learning_rate': 4.0688888888888894e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0626, 'grad_norm': 4.0443854331970215, 'learning_rate': 4.002222222222222e-05, 'epoch': 0.6}\n",
      "{'loss': 0.0733, 'grad_norm': 2.392822265625, 'learning_rate': 3.935555555555556e-05, 'epoch': 0.64}\n",
      "{'loss': 0.0556, 'grad_norm': 2.108177661895752, 'learning_rate': 3.868888888888889e-05, 'epoch': 0.68}\n",
      "{'loss': 0.06, 'grad_norm': 1.3299458026885986, 'learning_rate': 3.802222222222223e-05, 'epoch': 0.72}\n",
      "{'loss': 0.0577, 'grad_norm': 1.5351272821426392, 'learning_rate': 3.7355555555555556e-05, 'epoch': 0.76}\n",
      "{'loss': 0.0561, 'grad_norm': 1.0857595205307007, 'learning_rate': 3.668888888888889e-05, 'epoch': 0.8}\n",
      "{'loss': 0.052, 'grad_norm': 0.8516504168510437, 'learning_rate': 3.602222222222223e-05, 'epoch': 0.84}\n",
      "{'loss': 0.0474, 'grad_norm': 0.7313346266746521, 'learning_rate': 3.5355555555555555e-05, 'epoch': 0.88}\n",
      "{'loss': 0.0454, 'grad_norm': 2.8964734077453613, 'learning_rate': 3.468888888888889e-05, 'epoch': 0.92}\n",
      "{'loss': 0.0633, 'grad_norm': 1.5757354497909546, 'learning_rate': 3.402222222222222e-05, 'epoch': 0.96}\n",
      "{'loss': 0.0274, 'grad_norm': 2.5034618377685547, 'learning_rate': 3.3355555555555554e-05, 'epoch': 1.0}\n",
      "{'eval_loss': 0.0377529077231884, 'eval_f1': 0.9198738170347003, 'eval_runtime': 36.3849, 'eval_samples_per_second': 27.484, 'eval_steps_per_second': 0.22, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0636, 'grad_norm': 1.3048202991485596, 'learning_rate': 3.268888888888889e-05, 'epoch': 1.04}\n",
      "{'loss': 0.0311, 'grad_norm': 1.6440324783325195, 'learning_rate': 3.2022222222222224e-05, 'epoch': 1.08}\n",
      "{'loss': 0.0277, 'grad_norm': 0.6418254375457764, 'learning_rate': 3.135555555555555e-05, 'epoch': 1.12}\n",
      "{'loss': 0.0259, 'grad_norm': 0.7985669374465942, 'learning_rate': 3.068888888888889e-05, 'epoch': 1.16}\n",
      "{'loss': 0.0321, 'grad_norm': 0.11533275991678238, 'learning_rate': 3.0022222222222223e-05, 'epoch': 1.2}\n",
      "{'loss': 0.0262, 'grad_norm': 2.1946496963500977, 'learning_rate': 2.935555555555556e-05, 'epoch': 1.24}\n",
      "{'loss': 0.0309, 'grad_norm': 0.8636915683746338, 'learning_rate': 2.8688888888888894e-05, 'epoch': 1.28}\n",
      "{'loss': 0.0223, 'grad_norm': 3.0919342041015625, 'learning_rate': 2.8022222222222222e-05, 'epoch': 1.32}\n",
      "{'loss': 0.0249, 'grad_norm': 1.7206865549087524, 'learning_rate': 2.7355555555555557e-05, 'epoch': 1.3599999999999999}\n",
      "{'loss': 0.0289, 'grad_norm': 4.6070780754089355, 'learning_rate': 2.6688888888888892e-05, 'epoch': 1.4}\n",
      "{'loss': 0.0272, 'grad_norm': 0.09489529579877853, 'learning_rate': 2.6022222222222224e-05, 'epoch': 1.44}\n",
      "{'loss': 0.0284, 'grad_norm': 1.104198694229126, 'learning_rate': 2.5355555555555556e-05, 'epoch': 1.48}\n",
      "{'loss': 0.0281, 'grad_norm': 0.07814817130565643, 'learning_rate': 2.4688888888888888e-05, 'epoch': 1.52}\n",
      "{'loss': 0.0251, 'grad_norm': 0.08676781505346298, 'learning_rate': 2.4022222222222223e-05, 'epoch': 1.56}\n",
      "{'loss': 0.0274, 'grad_norm': 0.03589197248220444, 'learning_rate': 2.3355555555555555e-05, 'epoch': 1.6}\n",
      "{'loss': 0.0213, 'grad_norm': 4.136913776397705, 'learning_rate': 2.268888888888889e-05, 'epoch': 1.6400000000000001}\n",
      "{'loss': 0.0119, 'grad_norm': 1.444018840789795, 'learning_rate': 2.2022222222222225e-05, 'epoch': 1.6800000000000002}\n",
      "{'loss': 0.0218, 'grad_norm': 0.41846200823783875, 'learning_rate': 2.1355555555555557e-05, 'epoch': 1.72}\n",
      "{'loss': 0.0315, 'grad_norm': 0.7638266086578369, 'learning_rate': 2.0688888888888892e-05, 'epoch': 1.76}\n",
      "{'loss': 0.0266, 'grad_norm': 0.2994028925895691, 'learning_rate': 2.0022222222222224e-05, 'epoch': 1.8}\n",
      "{'loss': 0.0157, 'grad_norm': 0.8438137769699097, 'learning_rate': 1.9355555555555556e-05, 'epoch': 1.8399999999999999}\n",
      "{'loss': 0.0164, 'grad_norm': 1.3140795230865479, 'learning_rate': 1.8688888888888888e-05, 'epoch': 1.88}\n",
      "{'loss': 0.0083, 'grad_norm': 0.021378710865974426, 'learning_rate': 1.8022222222222223e-05, 'epoch': 1.92}\n",
      "{'loss': 0.0159, 'grad_norm': 0.29613304138183594, 'learning_rate': 1.7355555555555555e-05, 'epoch': 1.96}\n",
      "{'loss': 0.0285, 'grad_norm': 0.4822419583797455, 'learning_rate': 1.668888888888889e-05, 'epoch': 2.0}\n",
      "{'eval_loss': 0.03264262527227402, 'eval_f1': 0.9308814204185162, 'eval_runtime': 38.2637, 'eval_samples_per_second': 26.134, 'eval_steps_per_second': 0.209, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0086, 'grad_norm': 0.3652673065662384, 'learning_rate': 1.602222222222222e-05, 'epoch': 2.04}\n",
      "{'loss': 0.011, 'grad_norm': 0.03480139747262001, 'learning_rate': 1.5355555555555557e-05, 'epoch': 2.08}\n",
      "{'loss': 0.0079, 'grad_norm': 0.4935230314731598, 'learning_rate': 1.468888888888889e-05, 'epoch': 2.12}\n",
      "{'loss': 0.0076, 'grad_norm': 0.08843041956424713, 'learning_rate': 1.4022222222222222e-05, 'epoch': 2.16}\n",
      "{'loss': 0.0081, 'grad_norm': 0.10128812491893768, 'learning_rate': 1.3355555555555557e-05, 'epoch': 2.2}\n",
      "{'loss': 0.0066, 'grad_norm': 0.0034808507189154625, 'learning_rate': 1.268888888888889e-05, 'epoch': 2.24}\n",
      "{'loss': 0.0068, 'grad_norm': 0.033791378140449524, 'learning_rate': 1.2022222222222223e-05, 'epoch': 2.2800000000000002}\n",
      "{'loss': 0.0103, 'grad_norm': 0.29339855909347534, 'learning_rate': 1.1355555555555556e-05, 'epoch': 2.32}\n",
      "{'loss': 0.0043, 'grad_norm': 0.0006742799305357039, 'learning_rate': 1.068888888888889e-05, 'epoch': 2.36}\n",
      "{'loss': 0.0027, 'grad_norm': 0.00899495929479599, 'learning_rate': 1.0022222222222223e-05, 'epoch': 2.4}\n",
      "{'loss': 0.0131, 'grad_norm': 0.010361680760979652, 'learning_rate': 9.355555555555557e-06, 'epoch': 2.44}\n",
      "{'loss': 0.0098, 'grad_norm': 0.1283668428659439, 'learning_rate': 8.68888888888889e-06, 'epoch': 2.48}\n",
      "{'loss': 0.0179, 'grad_norm': 0.043002862483263016, 'learning_rate': 8.022222222222222e-06, 'epoch': 2.52}\n",
      "{'loss': 0.0048, 'grad_norm': 0.7466057538986206, 'learning_rate': 7.3555555555555555e-06, 'epoch': 2.56}\n",
      "{'loss': 0.0045, 'grad_norm': 0.032585278153419495, 'learning_rate': 6.688888888888889e-06, 'epoch': 2.6}\n",
      "{'loss': 0.0135, 'grad_norm': 0.005372903775423765, 'learning_rate': 6.0222222222222225e-06, 'epoch': 2.64}\n",
      "{'loss': 0.0131, 'grad_norm': 0.01722021773457527, 'learning_rate': 5.355555555555556e-06, 'epoch': 2.68}\n",
      "{'loss': 0.003, 'grad_norm': 0.05944663658738136, 'learning_rate': 4.6888888888888895e-06, 'epoch': 2.7199999999999998}\n",
      "{'loss': 0.0078, 'grad_norm': 2.0240421295166016, 'learning_rate': 4.022222222222222e-06, 'epoch': 2.76}\n",
      "{'loss': 0.0069, 'grad_norm': 0.36857321858406067, 'learning_rate': 3.3555555555555557e-06, 'epoch': 2.8}\n",
      "{'loss': 0.0081, 'grad_norm': 0.047232482582330704, 'learning_rate': 2.6888888888888892e-06, 'epoch': 2.84}\n",
      "{'loss': 0.0042, 'grad_norm': 0.2625269889831543, 'learning_rate': 2.0222222222222223e-06, 'epoch': 2.88}\n",
      "{'loss': 0.0072, 'grad_norm': 0.3450656831264496, 'learning_rate': 1.3555555555555556e-06, 'epoch': 2.92}\n",
      "{'loss': 0.0041, 'grad_norm': 0.6770726442337036, 'learning_rate': 6.888888888888889e-07, 'epoch': 2.96}\n",
      "{'loss': 0.0065, 'grad_norm': 0.0075021651573479176, 'learning_rate': 2.2222222222222224e-08, 'epoch': 3.0}\n",
      "{'eval_loss': 0.033213842660188675, 'eval_f1': 0.9489508299404947, 'eval_runtime': 35.7943, 'eval_samples_per_second': 27.937, 'eval_steps_per_second': 0.223, 'epoch': 3.0}\n",
      "{'train_runtime': 3153.5725, 'train_samples_per_second': 5.708, 'train_steps_per_second': 0.713, 'train_loss': 0.03971756872203615, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2250, training_loss=0.03971756872203615, metrics={'train_runtime': 3153.5725, 'train_samples_per_second': 5.708, 'train_steps_per_second': 0.713, 'train_loss': 0.03971756872203615, 'epoch': 3.0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e02661-0e54-4707-af1b-c74feb8fe478",
   "metadata": {},
   "source": [
    "### 10. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82f67d64-5e8f-41d1-baa3-b92f1a1ec6e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/envs/Advanced_AI/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03460295498371124, 'eval_f1': 0.9404969778374749, 'eval_runtime': 164.7689, 'eval_samples_per_second': 28.142, 'eval_steps_per_second': 0.225, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.03460295498371124,\n",
       " 'eval_f1': 0.9404969778374749,\n",
       " 'eval_runtime': 164.7689,\n",
       " 'eval_samples_per_second': 28.142,\n",
       " 'eval_steps_per_second': 0.225,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b567ca2-f350-4406-b9fa-4128aab822cc",
   "metadata": {},
   "source": [
    "### 11. Use the model to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ecfacd5-2653-4c56-a680-9d426526fc7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[[10.64678   , -2.239826  , -2.2844255 , ..., -2.6060598 ,\n",
       "         -0.81991184, -1.2551738 ],\n",
       "        [11.5474415 , -2.2178485 , -2.7366002 , ..., -3.2716274 ,\n",
       "         -1.1731164 , -2.7360775 ],\n",
       "        [11.684027  , -2.6310945 , -2.0666964 , ..., -2.5131216 ,\n",
       "         -2.2834492 , -1.7167438 ],\n",
       "        ...,\n",
       "        [ 7.6248655 , -0.48450452, -2.0787547 , ..., -2.9007163 ,\n",
       "          0.73124385, -2.8661065 ],\n",
       "        [ 7.445551  , -1.5348887 , -1.0170684 , ..., -1.3277225 ,\n",
       "         -0.65729487, -0.741101  ],\n",
       "        [ 5.2149487 , -1.2520466 , -2.4231222 , ..., -1.7960234 ,\n",
       "          3.3725803 , -0.70588726]],\n",
       "\n",
       "       [[10.880301  , -2.3322723 , -2.2843578 , ..., -2.507852  ,\n",
       "         -1.3147421 , -1.4865595 ],\n",
       "        [11.582846  , -2.6003728 , -2.2398748 , ..., -2.9084034 ,\n",
       "         -1.9265811 , -2.3096178 ],\n",
       "        [11.616342  , -2.7918046 , -1.8694113 , ..., -2.8674319 ,\n",
       "         -2.042788  , -1.936191  ],\n",
       "        ...,\n",
       "        [ 9.158684  , -1.8476    , -2.5163867 , ..., -2.657433  ,\n",
       "          0.39360675, -1.8744081 ],\n",
       "        [ 9.039915  , -2.0338662 , -2.5196857 , ..., -1.2842443 ,\n",
       "         -1.0555245 , -1.3931483 ],\n",
       "        [11.106148  , -2.2174447 , -1.842454  , ..., -2.2443419 ,\n",
       "         -1.4658409 , -1.0896789 ]],\n",
       "\n",
       "       [[10.740153  , -2.1174433 , -2.119467  , ..., -2.609108  ,\n",
       "         -1.2982566 , -1.4393482 ],\n",
       "        [11.795266  , -2.157904  , -2.363558  , ..., -3.6931453 ,\n",
       "         -1.479439  , -2.825827  ],\n",
       "        [11.952526  , -2.4953163 , -2.170025  , ..., -3.342752  ,\n",
       "         -1.6546907 , -2.1014438 ],\n",
       "        ...,\n",
       "        [11.348095  , -2.2676728 , -1.7204264 , ..., -2.4984002 ,\n",
       "         -2.3274512 , -1.4423254 ],\n",
       "        [11.090939  , -2.0096297 , -1.938341  , ..., -2.9538393 ,\n",
       "         -1.5057411 , -1.7578061 ],\n",
       "        [ 7.393622  , -1.9348848 , -1.9750649 , ..., -1.2235165 ,\n",
       "         -0.13906668, -0.11301898]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[10.615081  , -2.0371847 , -1.9773905 , ..., -2.5495548 ,\n",
       "         -1.2504721 , -1.5484133 ],\n",
       "        [11.302126  , -1.9632816 , -1.9394219 , ..., -2.8337889 ,\n",
       "         -2.0430162 , -2.4955726 ],\n",
       "        [11.36193   , -2.2758257 , -1.8546079 , ..., -3.1513991 ,\n",
       "         -1.6316098 , -2.863826  ],\n",
       "        ...,\n",
       "        [10.96452   , -2.6902587 , -1.3035077 , ..., -2.9092565 ,\n",
       "         -1.3067756 , -2.2252028 ],\n",
       "        [ 7.351652  , -1.4303795 , -0.8229381 , ..., -1.7182816 ,\n",
       "         -0.12900643, -1.8447065 ],\n",
       "        [ 8.903094  , -1.6088418 , -1.5759977 , ..., -2.2933435 ,\n",
       "         -0.5266551 , -2.2657866 ]],\n",
       "\n",
       "       [[10.749433  , -2.2657826 , -2.2247522 , ..., -2.5420613 ,\n",
       "         -1.2494785 , -1.6227118 ],\n",
       "        [11.820906  , -2.6916726 , -2.4360764 , ..., -2.8780763 ,\n",
       "         -1.9335403 , -2.0495958 ],\n",
       "        [11.66024   , -2.7940767 , -2.1439764 , ..., -2.8879476 ,\n",
       "         -2.0339622 , -1.9375017 ],\n",
       "        ...,\n",
       "        [11.624683  , -2.6655388 , -2.0253446 , ..., -2.8127947 ,\n",
       "         -1.5353135 , -1.6816049 ],\n",
       "        [11.615955  , -2.3999143 , -2.4071367 , ..., -3.0696054 ,\n",
       "         -1.3305044 , -1.9904763 ],\n",
       "        [11.176951  , -2.0278907 , -2.5399644 , ..., -3.5975673 ,\n",
       "         -0.41418028, -2.732267  ]],\n",
       "\n",
       "       [[ 5.4814525 ,  0.12622607, -0.75313354, ..., -0.6369722 ,\n",
       "         -1.8929455 , -0.48418334],\n",
       "        [ 4.6627903 , -1.3439698 ,  0.10983084, ...,  0.75636476,\n",
       "         -1.6521493 , -0.11921203],\n",
       "        [ 4.6640606 , -1.3445718 ,  0.25007364, ...,  0.76341933,\n",
       "         -1.676719  , -0.12441448],\n",
       "        ...,\n",
       "        [ 4.749775  , -1.2794218 , -0.02201729, ...,  0.59954655,\n",
       "         -1.3752688 , -0.26028043],\n",
       "        [ 4.756686  , -1.235306  , -0.06448783, ...,  0.5496318 ,\n",
       "         -1.3082575 , -0.3304289 ],\n",
       "        [ 4.750558  , -1.2716888 ,  0.02201413, ...,  0.62390625,\n",
       "         -1.4553915 , -0.25571972]]], dtype=float32), label_ids=array([[-100,    0,    0, ..., -100, -100, -100],\n",
       "       [-100,    0,    0, ..., -100, -100, -100],\n",
       "       [-100,    0,    0, ..., -100, -100, -100],\n",
       "       ...,\n",
       "       [-100,    0,    0, ..., -100, -100, -100],\n",
       "       [-100,    0,    0, ..., -100, -100, -100],\n",
       "       [-100, -100, -100, ..., -100, -100, -100]]), metrics={'test_loss': 0.03460295498371124, 'test_f1': 0.9404969778374749, 'test_runtime': 171.2567, 'test_samples_per_second': 27.076, 'test_steps_per_second': 0.216})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict(tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dee422-6467-4228-852c-37699eee3c26",
   "metadata": {},
   "source": [
    "### 12. Predict with single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "671c8556-44db-470f-b104-47160a7ea5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a55d8f18-9be8-419e-91f2-e1061dea23c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.id2label = {idx: label for idx, label in enumerate(label_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a894eb5-b0d4-4890-9f28-f40c70b73541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-PER',\n",
       "  'score': 0.9994832,\n",
       "  'index': 1,\n",
       "  'word': '张',\n",
       "  'start': 0,\n",
       "  'end': 1},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.999395,\n",
       "  'index': 2,\n",
       "  'word': '美',\n",
       "  'start': 1,\n",
       "  'end': 2},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9990043,\n",
       "  'index': 3,\n",
       "  'word': '肥',\n",
       "  'start': 2,\n",
       "  'end': 3},\n",
       " {'entity': 'B-LOC',\n",
       "  'score': 0.9981299,\n",
       "  'index': 7,\n",
       "  'word': '巴',\n",
       "  'start': 6,\n",
       "  'end': 7},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.99649304,\n",
       "  'index': 8,\n",
       "  'word': '布',\n",
       "  'start': 7,\n",
       "  'end': 8},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9958793,\n",
       "  'index': 9,\n",
       "  'word': '亚',\n",
       "  'start': 8,\n",
       "  'end': 9},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9366285,\n",
       "  'index': 10,\n",
       "  'word': '新',\n",
       "  'start': 9,\n",
       "  'end': 10},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9986533,\n",
       "  'index': 11,\n",
       "  'word': '几',\n",
       "  'start': 10,\n",
       "  'end': 11},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9985067,\n",
       "  'index': 12,\n",
       "  'word': '内',\n",
       "  'start': 11,\n",
       "  'end': 12},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9983771,\n",
       "  'index': 13,\n",
       "  'word': '亚',\n",
       "  'start': 12,\n",
       "  'end': 13},\n",
       " {'entity': 'B-ORG',\n",
       "  'score': 0.99746215,\n",
       "  'index': 18,\n",
       "  'word': '高',\n",
       "  'start': 17,\n",
       "  'end': 18},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.9985493,\n",
       "  'index': 19,\n",
       "  'word': '腰',\n",
       "  'start': 18,\n",
       "  'end': 19},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.9996985,\n",
       "  'index': 20,\n",
       "  'word': '集',\n",
       "  'start': 19,\n",
       "  'end': 20},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.9997118,\n",
       "  'index': 21,\n",
       "  'word': '团',\n",
       "  'start': 20,\n",
       "  'end': 21}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_pipe = pipeline(\"token-classification\",\n",
    "                    model = model,\n",
    "                    tokenizer = tokenizer,\n",
    "                    device = 0)\n",
    "ner_pipe(\"张美肥出生在巴布亚新几内亚，就职于高腰集团。\") #This will list out the named entity charater by character, and provide details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a58b5166-0921-45f1-8e03-fee20a313600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9992942,\n",
       "  'word': '张 美 肥',\n",
       "  'start': 0,\n",
       "  'end': 3},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9889525,\n",
       "  'word': '巴 布 亚 新 几 内 亚',\n",
       "  'start': 6,\n",
       "  'end': 13},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9988554,\n",
       "  'word': '高 腰 集 团',\n",
       "  'start': 17,\n",
       "  'end': 21}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_pipe = pipeline(\"token-classification\",\n",
    "                    model = model,\n",
    "                    tokenizer = tokenizer,\n",
    "                    device = 0, \n",
    "                    aggregation_strategy = \"simple\" #This will aggregate named entities\n",
    "                   )\n",
    "ner_pipe(\"张美肥出生在巴布亚新几内亚，就职于高腰集团。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eb7811-2f66-4213-9f5c-2061000c4374",
   "metadata": {},
   "source": [
    "Bert will automatically add space between characters after decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6673953d-2590-4b6f-8448-756c39bb0333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PER': ['张美肥'], 'LOC': ['巴布亚新几内亚'], 'ORG': ['高腰集团']}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = \"张美肥出生在巴布亚新几内亚，就职于高腰集团。\"\n",
    "result = ner_pipe(sen)\n",
    "\n",
    "ner_result = {}\n",
    "\n",
    "for r in result:\n",
    "    if r[\"entity_group\"] not in ner_result:\n",
    "        ner_result[r[\"entity_group\"]] = []\n",
    "    ner_result[r[\"entity_group\"]].append(sen[r[\"start\"]:r[\"end\"]])\n",
    "\n",
    "ner_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fdbce7-84f4-47a5-b5e5-32b1051a9260",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
